{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1a)\n",
    "First of, we handle boundary condition by implementing zero-pooling. Given that the stride is 1 and as the convolved image should perserve the spatial size we determine the size of zero-padding by\n",
    "\n",
    "$P = (F - 1) / 2 = (3 - 1) / 2 = 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -2.,   1., -11.,   2.,  13.],\n",
       "       [-10.,   4.,  -8.,  -2.,  18.],\n",
       "       [-14.,   1.,   5.,  -6.,   9.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "input_data = np.array(\n",
    "    [\n",
    "        [0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 1, 0, 2, 3, 1, 0],\n",
    "        [0, 3, 2, 0, 7, 0, 0],\n",
    "        [0, 0, 6, 1, 1, 4, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0]\n",
    "    ]\n",
    ")\n",
    "flipped_kernel = np.array([\n",
    "    [1, 0, -1],\n",
    "    [2, 0, -2],\n",
    "    [1, 0, -1]\n",
    "])\n",
    "\n",
    "convolved_output = np.zeros((3,5))\n",
    "\n",
    "for i in range(1, input_data.shape[0]-1):\n",
    "    for j in range(1, input_data.shape[1]-1):\n",
    "        convolved_output[i-1, j-1] = np.sum(np.multiply(kernel, input_data[i-1:i+2, j-1:j+2]))\n",
    "        \n",
    "convolved_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the spatial convolution, the original kernel/filter is flipped. Spatial convolution gives us the following output:\n",
    "\n",
    "$\n",
    "\\begin{bmatrix}\n",
    "    -2 & 1 & -11 & 2 & 13 \\\\\n",
    "    -10 & 4 & -8 & -2 & 18 \\\\\n",
    "    -14 & 1 & 5 & -6 & 9 \\\\\n",
    "\\end{bmatrix}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1b)\n",
    "(iii) Max Pooling.\n",
    "\n",
    "Max pooling increases invariance to translation as it disregards the spatial information, but keeps the max value in the area of inspection.\n",
    "\n",
    "Why not (i) - Convolutional layer? From a mere intuitive standpoint, comparing how the output of a convolutional layer and a max pooling layer is calculated, it seems self explanatory that the max pooling is less prone to translational variations. If we look at the filter used in task 1a), a translational shift will also shift the outputs. Max pooling discards spatial information - and \"only cares about\" the max value in the area, meaning that the layer will give the same output even if the input is shifted.\n",
    "\n",
    "Why not (ii) activation function? Does not make sense (?).\n",
    "\n",
    "## Task 1c)\n",
    "Similar to task 1a, we wish to perserve the spatial size through convolution.  Using the same formula, with:\n",
    "$S = 1$\n",
    "and\n",
    "$F = 5$\n",
    "\n",
    "$P = (F - 1) / 2 = (5 - 1) / 2 = 2$\n",
    "\n",
    "## Task 1d)\n",
    "Given equal width and height, we only need to calculate one of the dimensions. Calculating width:\n",
    "\n",
    "$W_{2} = \\frac{W_{1} - F + 2P}{S} + 1$\n",
    "\n",
    "$F = -(W_{2}-1)S + W_{1} + 2P$\n",
    "\n",
    "which gives, with our values:\n",
    "\n",
    "$F = -(504-1)*1 + 512 + 2*0 = 9 $\n",
    "\n",
    "(Height) x (Width) is 9x9. Depth = K = 12.\n",
    "\n",
    "\n",
    "## Task 1e)\n",
    "Pooling layers accepts a volume of size W, H D, and takes hyperparameters F and S as input.\n",
    "\n",
    "The layer produces a volume of size: \n",
    "$W_{2} = \\frac{W_{1} - F}{S} + 1$\n",
    "\n",
    "As we are working with equal width and height, we only have to calculate one of them:\n",
    "\n",
    "$ W_{2} = \\frac{W_{1} - F}{S} + 1 = \\frac{504 - 2}{2} + 1 = 252$\n",
    "\n",
    "The layer produces an output of size: (Height) x (Width) = 252x252. Depth is perserved.\n",
    "\n",
    "## Task 1f)\n",
    "Using the same equation as in task 1d. We now have input, assuming output from the pooling layer in task 1e, of size W,H,D = 252, 252, 12.\n",
    "Again, equal height and width:\n",
    "\n",
    "$W_{2} = \\frac{W_{1} - F + 2P}{S} + 1 = \\frac{252 - 3}{1} + 1 = 250 $ \n",
    "\n",
    "The size of the feature maps: (Height) x (Width) = 250x250\n",
    "\n",
    "## task 1g)\n",
    "390336\n",
    "Legger inn tabellen fra excel når dobbeltsjekket at riktig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "\n",
    "### Task 2a)\n",
    "![](plots/task2_plot.png)\n",
    "### Task 2b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3a)\n",
    "Report your two models. Describe the network architecture (similar to Table 1) and include\n",
    "training details such as optimizer, regularization, learning rate, batch size, weight initialization and\n",
    "other details that are required such that a person reading it can closely replicate your results.\n",
    "\n",
    "#### Network 1\n",
    "Network one is implemented with batch size ..., 10 epochs, initial learning rate ... and early stopping count ..., and the architecture described in the table below. For the dropout layer we choose to increase the dropout rate each time, starting with 20% probability and increasing with 10% for each time, ending up with 50% probability between the fully conected layer. The convolutional layers used a kernel size of 3, and padding and stride of 1, and was implemented with ReLU activation function. Every  pooling layers used a kernel size of 2x2, and stride of 2. \n",
    "The weights was initilazed with ... and we used the SGD optimizer. \n",
    "Further on we tried agumentation to exted our dataset. We used three different transformations: random horizontal flip, .... \n",
    "\n",
    "| Layer | Layer Type  | Number of Hidden Units/Number of Filters    | Activation Function   |\n",
    "|---:|:-------------|:-----------:|:------|\n",
    "| 1 | Conv2d  | 32  | ReLU   | \n",
    "| 1 | BatchNorm2d  | -   | -   | \n",
    "| 2 | Conv2d  | -  | ReLU   | \n",
    "| 2 | BatchNorm2d  | -   | -   | \n",
    "| 2 | MaxPool2d  | -  | -  | \n",
    "| 2 | Dropout  | -   | -   | \n",
    "| 3 | Conv2d  | 64 | ReLU   | \n",
    "| 3 | BatchNorm2d  | -   | -   | \n",
    "| 3 | Conv2d  | -   | ReLU   | \n",
    "| 3 | BatchNorm2d  | -   | -   | \n",
    "| 3 | MaxPool2d  | -  | -  | \n",
    "| 3 | Dropout  | -   | -   | \n",
    "| 4 | Conv2d  | 128  | ReLU   | \n",
    "| 4 | BatchNorm2d  | -   | -   | \n",
    "| 4 | Conv2d  | -   | ReLU   | \n",
    "| 4 | BatchNorm2d  | -   | -   | \n",
    "| 4 | MaxPool2d  | -  | -  | \n",
    "| 4 | Dropout  | -   | -   |\n",
    "|   | Flatten  | -  | -  | \n",
    "| 6 | Fully-Connected  | 64   | ReLU  | \n",
    "| 6 | Dropout  | -   | -   |\n",
    "| 7 | Fully-Connected  | 10   | Softmax   | \n",
    "\n",
    "#### Network 2\n",
    "For the second Network we used the same hyperparameters as for network 1. We changed the architecture and choosed to apply one more layer with trainable layer compared to the network in task 2. The architecture described in the table below. For this network we did not implement any regularization, but choose to replace all the ReLU activation functions with LeakyReLU.  The convolutional layers used a kernel size of 5, padding of 2 and stride of 1. Every  pooling layers used a kernel size of 2x2, and stride of 2. \n",
    "The weights was initilazed with ... and we used the Adam optimizer. \n",
    "\n",
    "| Layer | Layer Type  | Number of Hidden Units/Number of Filters    | Activation Function   |\n",
    "|---:|:-------------|:-----------:|:------|\n",
    "| 1 | Conv2d  | 32  | LeakyReLU   | \n",
    "| 1 | MaxPool2d  | -  | -  | \n",
    "| 2 | Conv2d  | 64 | LeakyReLU   | \n",
    "| 2 | MaxPool2d  | -  | -  | \n",
    "| 3 | Conv2d  | 128  | LeakyReLU   | \n",
    "| 3 | MaxPool2d  | -  | -  | \n",
    "| 4 | Conv2d  | 256  | LeakyReLU   | \n",
    "| 4 | MaxPool2d  | -  | -  | \n",
    "|   | Flatten  | -  | -  | \n",
    "| 5 | Fully-Connected  | 64   | LeakyReLU  | \n",
    "| 6 | Fully-Connected  | 10   | Softmax   | \n",
    "\n",
    "\n",
    "### Task 3b)\n",
    "Include a table including the final train loss, training accuracy, validation accuracy and\n",
    "test accuracy for the two models. This should all be in one table.\n",
    "\n",
    "Final statistics from the two models. \n",
    "\n",
    "| Network  | 1 | 2  |\n",
    "|--------:|:---:|:---:|\n",
    "| Training Loss | 0. | 0.  |  \n",
    "| Training Accuracy | 0. | 0.  |  \n",
    "| Validation Accuracy | 0. | 0.  |  \n",
    "| Test Accuracy | 0. | 0.  |  \n",
    "\n",
    "Include a plot of the validation accuracy vs the number of training steps for your best model.\n",
    "Include a plot of training, and validation loss vs the number of training steps for your best model.\n",
    "### Task 3c)\n",
    "Discuss briefly what methods you found useful, and answer the following questions.\n",
    "• Which method did you see the improvement with? Why do you think the network improved\n",
    "with this method?\n",
    "• Which method did not work? Why did it not work?\n",
    "### Task 3d)\n",
    "For the method/technique that you saw the largest amount of improvement on, include a\n",
    "plot of the train and validation loss before/after applying this technique (Similar to what you did\n",
    "in task 3 for assignment 2). Remember to include this in the same graph!\n",
    "### Task 3e)\n",
    "Improve on your best model and reach an accuracy of 80% on the test set within 10 epochs.\n",
    "Include a plot of validation accuracy over training, and report your final test accuracy\n",
    "### Task 3f)\n",
    "] For your best model, do you see any signs of overfitting or underfitting?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4a)\n",
    "| Hyperparameters|  |\n",
    "|:-------|----------|\n",
    "|Epochs|10 |\n",
    "|Batch Size|32 |\n",
    "|Learning Rate|0.0005|\n",
    "|Early Stop Count |4 |\n",
    "\n",
    "![](plots/task4_plot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4b)\n",
    "Filter activation one and two detect lines, the first activating on vertical lines and the second on horizontal lines. Plots 3 and 5 seem to be activated by larger features, _plot 3_ on the sky and on the zebra, _plot 5_ on the grass, both filter the image in a \"gaussian way\" - blurring out smaller details. Even though _Plot 4_ is dominated by one shade of grey, the zebra is still easily identifiable. Thus, we believe _Plot 4_ activates on contrasts or edges.\n",
    "![](plots/task_4b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4c)\n",
    "To get a better impression of what the activation looks like after the last convolution layer, the zebra is set as a background and the activations are made transparent. Several of the activations are focused around the head and body area of the zebra. What might be of more interest, is the fact the we see very little activation in areas without the zebra (i.e. top right corner).\n",
    "![](plots/task_4c_w_zebra.png)\n",
    "\n",
    "![](plots/task_4c.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
