{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an outline for your report to ease the amount of work required to create your report. Jupyter notebook supports markdown, and I recommend you to check out this [cheat sheet](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet). If you are not familiar with markdown.\n",
    "\n",
    "Before delivery, **remember to convert this file to PDF**. You can do it in two ways:\n",
    "1. Print the webpage (ctrl+P or cmd+P)\n",
    "2. Export with latex. This is somewhat more difficult, but you'll get somehwat of a \"prettier\" PDF. Go to File -> Download as -> PDF via LaTeX. You might have to install nbconvert and pandoc through conda; `conda install nbconvert pandoc`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1a)\n",
    "\n",
    "![](task1a_logreg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1b)\n",
    "![](task1b_softmax1.png)\n",
    "\n",
    "![](task1b_softmax2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2b)\n",
    "![](task2b_binary_train_loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2c)\n",
    "![](task2b_binary_train_accuracy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2d)\n",
    "Early Stopping kicks in at Epoch 33 when using ```shuffle = False```.\n",
    "\n",
    "\n",
    "Early Stopping kicks in at Epoch 18 when using ```shuffle = True```.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2e)\n",
    "\n",
    "The accuracy without shuffle has spikes as it contains a batch that the model performes significantly worse on than the rest. This batch appears at around the same time for each epoch - giving us evenly spaced out spikes whenever it appears.\n",
    "\n",
    "Shuffeling solves this problem as the model is presented new, random, batches each epoch.\n",
    "\n",
    "![](task2e_train_accuracy_shuffle_difference.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3b)\n",
    "![](task3b_softmax_train_loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3c)\n",
    "![](task3b_softmax_train_accuracy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3d)\n",
    "As the plot shows, there is a growing gap between training accuarcy and validation accuracy. Such a trend could suggest overfitting. However, continuously increasing accuracy of the validation set argues otherwise. We believe that as long as the model is not trained on the validation set, an increase in validation accuracy is a positive event. \n",
    "\n",
    "If the Validation Accuracy trend was decreasing or flat, steps to reduce overfitting (ie. Early Stopping) would have to be implemented. Early stopping could be implemented in a more strict way - for example requiring a minimum increase in val. accuracy over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4a)\n",
    "\n",
    "Fill in image of hand-written notes which are easy to read, or latex equations here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4b)\n",
    "With regularization a lot of noise is filtered out. The picture on the top have lambda = 0, and therefore no regularization, which gives more noise. With lambda = 1, the noise is filtered out, there is no overfitting to the training data.\n",
    "\n",
    "![](task4b_softmax_weight.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4c)\n",
    "Regularization is implemented to reduce overfitting. It achieves this by penalizing the size of the weights. By adding a penalty term to the equation (which is to be minimized) the resulting model will avoid oversizing weights - and hopefully be able to give generalized and better predictions. \n",
    "\n",
    "That said, the value of lambda (size of penalty term) has to be tested to establish the best value. A large lambda can penalize weights too much - causing underfitting. Choosing ```lambda``` is a trade-off between overfitting and accuracy. \n",
    "\n",
    "As seen in our plots:\n",
    "\n",
    "```lambda = 1``` underfits the model.\n",
    "\n",
    "```lambda = 0.1``` underfits less than ```lambda = 1```, but still suboptimal.\n",
    "\n",
    "```lambda = 0.01``` and ```lambda = 0.001``` acheive very similar results.\n",
    "\n",
    "As the model trained with ```lambda = 0.01``` acheives similar results to ```lambda = 0.001```. We would prefer the model with ```lambda = 0.01``` as it is less likely to be overfit.\n",
    "\n",
    "![](task4c_l2_reg_accuracy_without_es.png)\n",
    "\n",
    "![](task4c_l2_reg_accuracy.png)\n",
    "ES kicks in, Step, Epoch:  279, 1\n",
    "\n",
    "ES kicks in, Step, Epoch:  1891, 12\n",
    "\n",
    "ES kicks in, Step, Epoch:  7006, 44\n",
    "\n",
    "ES kicks in, Step, Epoch:  7719, 49"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4d)\n",
    "![](task4d_l2_reg_norms.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4e)\n",
    "When lambda increase the lengths of the L2 norm decreases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
