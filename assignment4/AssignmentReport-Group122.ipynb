{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an outline for your report to ease the amount of work required to create your report. Jupyter notebook supports markdown, and I recommend you to check out this [cheat sheet](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet). If you are not familiar with markdown.\n",
    "\n",
    "Before delivery, **remember to convert this file to PDF**. You can do it in two ways:\n",
    "1. Print the webpage (ctrl+P or cmd+P)\n",
    "2. Export with latex. This is somewhat more difficult, but you'll get somehwat of a \"prettier\" PDF. Go to File -> Download as -> PDF via LaTeX. You might have to install nbconvert and pandoc through conda; `conda install nbconvert pandoc`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1a)\n",
    "Intersection-over-Union is a validation metric that calculates the ratio of the intersected area and union area of a predicted bounding box and the ground truth bounding box.\n",
    "![](task1a.png)\n",
    "In the illustration above. The ground truth bounding box is the green outline, the predicted bounding box is the red outline. Grey is the intersection and Grey+Blue is the union.\n",
    "\n",
    "$ IoU = \\frac{Intersection}{Union} = \\frac{Grey}{Grey+Blue}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1b)\n",
    "A true positive (TP) is a correctly labeled prediction of an item belonging to the positive class. A false positive (FP) is a incorrectly labeled prediction of an item belonging to the positive class.\n",
    "\n",
    "Precision is the ratio of positive predictions that are correct.\n",
    "\n",
    "$ Precision = \\frac{TP}{TP+FP}$\n",
    "\n",
    "Recall is correct positives found over all existing positives in the ground truth.\n",
    "\n",
    "$ Recall = \\frac{TP}{TP+FN}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP Class 1:  0.6454545454545455\n",
      "mAP Class 2:  0.6363636363636364\n",
      "mAP:  0.6409090909090909\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "precision_1 = [1.0, 1.0, 1.0, 0.5, 0.20]\n",
    "recall_1 = [0.05, 0.1, 0.4, 0.7, 1.0]\n",
    "precision_2 = [1.0, 0.80, 0.60, 0.5, 0.20]\n",
    "recall_2 = [0.3, 0.4, 0.5, 0.7, 1.0]\n",
    "\n",
    "# By hand:\n",
    "# 1 + 1 + 1 + 1 + 1 + .5 + .5 + .5 + .2 + .2 + .2 = .6455\n",
    "# 1 + 1 + 1 + 1 + .8 + .6 + .5 + .5 + .2 + .2 + .2 = .6364\n",
    "# avg = .6409\n",
    "\n",
    "# Implementation used in 2e. The recall-level variable: \"recall\" is rounded to 1 decimal as np.linspace was not able to produce\n",
    "# the desr\n",
    "avg_precision_1 = 0\n",
    "avg_precision_2 = 0\n",
    "for recall in np.linspace(0, 1.0, 11): \n",
    "    precisions_to_right_1 = [p for p, r in zip(precision_1, recall_1) if r >= round(recall,1)]\n",
    "    precisions_to_right_2 = [p for p, r in zip(precision_2, recall_2) if r >= round(recall,1)]\n",
    "    avg_precision_1 += max(precisions_to_right_1)\n",
    "    avg_precision_2 += max(precisions_to_right_2)\n",
    "\n",
    "avg1 = avg_precision_1/11\n",
    "avg2 = avg_precision_2/11\n",
    "\n",
    "print(\"mAP Class 1: \", avg1)\n",
    "print(\"mAP Class 2: \", avg2)\n",
    "print(\"mAP: \", (avg1+avg2)/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "\n",
    "### Task 2f\n",
    "![](task2/precision_recall_curve.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3a)\n",
    "The process of filtering out a set of overlapping boxes is called non-maximum suppression.\n",
    "\n",
    "### Task 3b)\n",
    "False; The first layers are better at detecting small objects, not the deeper layers. The first layers analyze the image at higher resolutions, thus having better conditions for small-object detection.\n",
    "\n",
    "### Task 3c)\n",
    "As different objects have different shapes, we wish to use various aspect-ratios for bounding boxes. An object's shape has a typical ratio, e.g., humans typically have the ratio 0.41 (which equates to high and narrow rectangle). We use different ratios to be able to detect the different objects in the image. This makes us able to cover various input object sizes and shapes. Using a variety of default box shapes/aspect ratios makes the task of predicting bounding boxes easier for the network. \n",
    "\n",
    "### Task 3d)\n",
    "The main difference is that YOLOv1/v2 uses a single scale feature map while SSD uses a multi-scale feature map.\n",
    "\n",
    "### Task 3e)\n",
    "We have that WxHxK = 38x38x6 = 8664\n",
    "\n",
    "### Task 3f)\n",
    "For each resolution:\n",
    "\n",
    "38x38: 38x38x6 = 8664\n",
    "\n",
    "19x19: 19x19x6 = 2166\n",
    "\n",
    "10x10: 10x10x6 = 600\n",
    "\n",
    "5x5: 5x5x6 = 150\n",
    "\n",
    "3x3: 3x3x6 = 54\n",
    "\n",
    "1x1: 1x1x6 = 6\n",
    "\n",
    "Total: 8664 + 2166 + 600 + 150 + 54 + 6 = 11640"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4b)\n",
    "Final mAP was 80.11% after 10 000 iterations. \n",
    "\n",
    "![](SSD/notebooks/basic_plot.png)\n",
    "\n",
    "## Task 4c/d)\n",
    "To improve our model we first implemented batch normalization, before all the activation functions, which improved the model by 3% and achieved an mAP of 83.03%. Second we changed the activation functions to LeakyReLU, with a = 0.005, we tried with a equal to 0.01, 0.1, and 0.2, but this decreased the mAP. With a=0.005 the mAP resulted in 82.26%. We changed the optimizer to Adam, which gave a small improvement and achieved mAP on 83.38%. Further on we changed the min box sizes because some of the numbers in the picture are quite small. We changed each variable in MODEL.PRIORS.MIN by 20 pixels, and achieved a mAP on 84%. \n",
    "Our model was quite unstable during training and therefore we decreased the learning rate to 2e^(-4), which gave a quite significant improvement with an mAP around 89%. Here it could also be an idea to decrease the learning rate during training, since decreasing the learning rate makes the model learn slower. The model was still a little bit unstable and usually decreased a little by the end of the training which showed a tendency of overfitting. Therefore, we increased the weight decay, and by that implementing an even harder L2 regularization to avoid overfitting. This did not change the final mAP significantly, but made the model more stable and avoided a big decrease at the end of training.\n",
    "\n",
    "Final mAP was 89.44% after 10 000 iterations. \n",
    "\n",
    "Plot over total loss is included below, with loss on the y-axis and iteration on the x-axis. \n",
    "\n",
    "![](SSD/notebooks/basicimproved_plot.png)\n",
    "\n",
    "\n",
    "## Task 4e)\n",
    "There were several digits the model did not detect, from the images we can see that it is an overweight of digits smaller in size that the model could not detect. This could caused by not haing small enough bounding boxes.\n",
    "\n",
    "\n",
    "![](SSD/demo/mnist/result/0.png)\n",
    "![](SSD/demo/mnist/result/1.png)\n",
    "![](SSD/demo/mnist/result/2.png)\n",
    "![](SSD/demo/mnist/result/3.png)\n",
    "![](SSD/demo/mnist/result/4.png)\n",
    "![](SSD/demo/mnist/result/5.png)\n",
    "![](SSD/demo/mnist/result/6.png)\n",
    "![](SSD/demo/mnist/result/7.png)\n",
    "![](SSD/demo/mnist/result/8.png)\n",
    "![](SSD/demo/mnist/result/9.png)\n",
    "\n",
    "\n",
    "## Task 4f)\n",
    "Final mAP was 21.72% after 5000 iterations. \n",
    "\n",
    "![](SSD/notebooks/vgg_plot.png)\n",
    "![](SSD/demo/voc/result/000342.png)\n",
    "![](SSD/demo/voc/result/000542.png)\n",
    "![](SSD/demo/voc/result/003123.png)\n",
    "![](SSD/demo/voc/result/004101.png)\n",
    "![](SSD/demo/voc/result/008591.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
